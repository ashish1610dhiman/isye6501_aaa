---
title: "mlr_assg4"
output: html_document
date: "2022-09-20"
---

```{r setup, include=FALSE}
library(cowplot)
library(ggplot2)
library(reshape2)
library(grid)
```


```{r crimes}
crime_data<-read.table(file = "./uscrime.txt", sep = "\t",header=TRUE)
head(crime_data)
dim(crime_data)
summary(crime_data)
```

#### Data Distribution and Pairwise Corelation
### Data Distribution
```{r}
my_plots <- lapply(names(crime_data), function(var_x){
  p <- 
    ggplot(crime_data) +
    aes_string(var_x)

  if(var_x %in% list("So")) {
    p <- p + geom_bar()

  } else {
    p <- p + geom_density()
  } 

})

plot_grid(plotlist = my_plots)

### Correlation
cormat <- round(cor(crime_data),2)
cormat[upper.tri(cormat)] <- NA
melted_cormat <- melt(cormat)
# plotting the correlation heatmap
library(ggplot2)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2,
                                   fill=value)) +
geom_tile() +
geom_text(aes(Var1, Var2, label = value),
          color = "white", size = 3)
```
## Observations: 
Wealth and Income Inequality are 2 highly correlated variables (-ve correlation) ,hence we can pick only 1 variable out of the 2
Po1 and Po2 are 2 correlated variables , hence we can pick only 1 out of 2 
Same goes for U1 and U2, , hence we can pick only 1 out of 2 

The dependent variable Crime Rate has high correlation with the following variables :
Po1 and Po2 -> we see a surprising +ve correlation with crime rate , As regression cannot be used for defining a causal relation , we can infer the other way round that since the crime rate is higher , that could be the reason of a higher per capita expenditure on police protection.

Prob -> makes sense to have -ve correlation in this case . As the crime rate is bound to decrease if probability of imprisonment increases.

```{r}
options(scipen=999)
crime_data$So<-as.factor(crime_data$So)
# Linear Regression model with all features
lmodel_1<-lm(Crime~M+So+Ed+Po1+Po2+LF+M.F+Pop+NW+U1+U2+Wealth+Ineq+Prob+Time,data=crime_data)
summary(lmodel_1)
# plotting the residuals to check for assumptions in the plain vanilla model with all features
par(mfrow = c(2, 2))
plot(lmodel_1)

new_datapoint<-data.frame(M=c(14.0),So=c(as.factor(0)),Ed=c(10.0),Po1=c(12.0),Po2=c(15.5),LF=c(0.640),M.F=c(94.0),Pop=c(150),NW=c(1.1),U1=c(0.120),U2=c(3.6),Wealth=c(3200),Ineq=c(20.1),Prob=c(0.04),Time=c(39.0))
crime_rate_pred<-predict(lmodel_1,newdata = new_datapoint)
crime_rate_pred
```
# Interpreting the output of the linear regression model : 

```{r}
options(scipen=999)
crime_data$So<-as.factor(crime_data$So)
# Linear Regression model with all features
lmodel_2<-lm(log(Crime)~M+So+Ed+Po1+Po2+LF+M.F+Pop+NW+U1+U2+Wealth+Ineq+Prob+Time,data=crime_data)
summary(lmodel_2)
# plotting the residuals to check for assumptions in the plain vanilla model with all features
par(mfrow = c(2, 2))
plot(lmodel_2)

new_datapoint<-data.frame(M=c(14.0),So=c(as.factor(0)),Ed=c(10.0),Po1=c(12.0),Po2=c(15.5),LF=c(0.640),M.F=c(94.0),Pop=c(150),NW=c(1.1),U1=c(0.120),U2=c(3.6),Wealth=c(3200),Ineq=c(20.1),Prob=c(0.04),Time=c(39.0))
crime_rate_pred<-predict(lmodel_2,newdata = new_datapoint)
crime_rate_pred<- exp(crime_rate_pred)
crime_rate_pred
```

```{r}
# removing the potential outliers/influential points based on the diagnostic plots of linear regression model
crime_data_wo<-crime_data[-c(11, 19, 46),]
dim(crime_data_wo)
# Linear Regression model with all features on the reduced dataset
lmodel_2<-lm(log(Crime)~M+So+Ed+Po1+Po2+LF+M.F+Pop+NW+U1+U2+Wealth+Ineq+Prob+Time,data=crime_data_wo)
summary(lmodel_2)
```


```{r}
new_datapoint<-data.frame(M=c(14.0),So=c(as.factor(0)),Ed=c(10.0),Po1=c(12.0),Po2=c(15.5),LF=c(0.640),M.F=c(94.0),Pop=c(150),NW=c(1.1),U1=c(0.120),U2=c(3.6),Wealth=c(3200),Ineq=c(20.1),Prob=c(0.04),Time=c(39.0))
crime_rate_pred<-predict(lmodel_4,newdata = new_datapoint)
crime_rate_pred
```
```{r}
crime_data[c(4,26),]
```


```{r}
# Linear Regression Model with Limited features (removing highly correlated features)
lmodel_2<-lm(Crime~M+So+Ed+Po1+LF+M.F+Pop+NW+U1+Ineq+Prob+Time,data=crime_data)
summary(lmodel_2)

par(mfrow = c(2, 2))
plot(lmodel_2)
```



```{r}
crime_data_wo<-crime_data[-c(11,19,29),]
dim(crime_data_wo)
# Linear Regression model with all features
lmodel_1<-lm(Crime~M+So+Ed+Po1+Po2+LF+M.F+Pop+NW+U1+U2+Wealth+Ineq+Prob+Time,data=crime_data_wo)
summary(lmodel_1)
# Linear Regression Model with Limited features (removing highly correlated features)
lmodel_4<-lm(Crime~M+So+Ed+Po1+LF+M.F+Pop+NW+U1+Ineq+Prob+Time,data=crime_data)
summary(lmodel_4)

```


```{r}
# Plot after removing the outliers/leverage points
par(mfrow = c(2, 2))
plot(lmodel_4)
```

```{r}
crime_data_wo<-crime_data[-c(11,19,29,46),]
dim(crime_data_wo)
# Linear Regression model with all features
lmodel_5<-lm(Crime~M+So+Ed+Po1+Po2+LF+M.F+Pop+NW+U1+U2+Wealth+Ineq+Prob+Time,data=crime_data_wo)
summary(lmodel_5)
# Linear Regression Model with Limited features (removing highly correlated features)
lmodel_6<-lm(Crime~M+So+Ed+Po1+LF+M.F+Pop+NW+U1+Ineq+Prob+Time,data=crime_data_wo)
summary(lmodel_6)
```